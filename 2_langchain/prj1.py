import streamlit as st
from langchain_core.messages.chat import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
st.title("â˜‘ï¸ë‚˜ë§Œì˜ ì±—GPT í…ŒìŠ¤íŠ¸ğŸ˜‚")
from dotenv import load_dotenv
load_dotenv()

if "messages" not in st.session_state:
    st.session_state["messages"] = []
    
with st.sidebar:
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")
    if clear_btn:
        st.session_state["messages"] = []
        
def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)
        
def add_messages(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))
    
def create_chain():
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤"),
        ("user", "#Question:\n{question}")
    ])
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
    output_parser = StrOutputParser()
    
    chain = prompt | llm | output_parser
    return chain

print_messages()

user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

if user_input:
    st.chat_message("user").write(user_input)
    chain = create_chain()
    response = chain.invoke({"question": user_input})
    with st.chat_message("assistant"):
        container = st.empty()
        ai_answer = ""
        for token in response:
            ai_answer += token
            container.markdown(ai_answer)
            
    add_messages("user", user_input)
    add_messages("assistant", ai_answer)